{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in the processed data and mapping the target column to binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engin = pd.read_csv(\"nonsparsetheta.csv\")\n",
    "engin = engin.drop('Unnamed: 0', axis=1)\n",
    "engin['y'] = np.where(engin['target'] == engin['player1_name'],\n",
    "                              'player1',\n",
    "                              'player2')\n",
    "m = {\"player1\": 0, \"player2\": 1}\n",
    "engin['maptarget'] = engin['y'].map(m)\n",
    "engin = engin.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engin.columns\n",
    "enginx = engin[[\n",
    "    \"player1_age\", \n",
    "    \"player2_age\", \n",
    "    \"player1_ht\", \n",
    "    \"player2_ht\", \n",
    "    \"player1_rank\", \n",
    "    \"player2_rank\", \n",
    "    \"player1_h2h\", \n",
    "    \"player2_h2h\",\n",
    "    \"surface\", \n",
    "    \"tourney_level\",\n",
    "    \"player_1_recent_form\",\n",
    "    \"player_2_recent_form\",\n",
    "    \"player_1_theta_form\",\n",
    "    \"player_2_theta_form\",\n",
    "    'player1_surface_win_pct', \n",
    "    'player2_surface_win_pct',\n",
    "    'player1_level_win_pct', \n",
    "    'player2_level_win_pct',]]\n",
    "enginy = engin['maptarget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "enginx['surface'] = le.fit_transform(enginx['surface'])\n",
    "enginx['tourney_level'] = le.fit_transform(enginx['tourney_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engintrainx, engintestx, engintrainy, engintesty = train_test_split(enginx, enginy, test_size=0.25, random_state=5323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipline for cross-validation and model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model, X, y, cv=100):\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             cv=cv,\n",
    "                             scoring=scoring,\n",
    "                             return_train_score=True,\n",
    "                             return_estimator=True)\n",
    "    return {\n",
    "            \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "            \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "            \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "            \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "            \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "            \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "            \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "            \"Mean Validation F1 Score\": results['test_f1'].mean(),\n",
    "            \"model\": results\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(solver='liblinear')\n",
    "logit_result = cv(logit, X=engintrainx, y = engintrainy, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "#randomized grid search cv to find the best range \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [False]\n",
    "\n",
    "randomgrid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = randomgrid, n_iter = 2, cv = 3, verbose=2, random_state=5323)\n",
    "rf_random.fit(engintrainx, engintrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rft = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    max_depth=20,\n",
    "    bootstrap=False)\n",
    "\n",
    "rft.fit(engintrainx, engintrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "preds = rft.predict(engintestx)\n",
    "accuracy_score(engintesty, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(engintrainx.columns, rft.feature_importances_)\n",
    "plt.title(\"Feature importance per RF model\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost doesn't play nice with the cv method I made \n",
    "#xgresults = cv(model=xgb, X = engintrainx, y = engintrainy, cv=10)\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(engintrainx, engintrainy)\n",
    "xgp = xgb.predict(engintestx)\n",
    "accuracy_score(engintesty, xgp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the confidence metric using logistic regression. Is it needed or does rank cover it well enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enginxwithout = engin[[\n",
    "    \"player1_age\", \n",
    "    \"player2_age\", \n",
    "    \"player1_ht\", \n",
    "    \"player2_ht\", \n",
    "    \"player1_rank\", \n",
    "    \"player2_rank\", \n",
    "    \"player1_h2h\", \n",
    "    \"player2_h2h\",\n",
    "    \"surface\", \n",
    "    \"tourney_level\",\n",
    "    'player1_surface_win_pct', \n",
    "    'player2_surface_win_pct',\n",
    "    'player1_level_win_pct', \n",
    "    'player2_level_win_pct',]]\n",
    "\n",
    "enginxwith = engin[[\n",
    "    \"player1_age\", \n",
    "    \"player2_age\", \n",
    "    \"player1_ht\", \n",
    "    \"player2_ht\", \n",
    "    \"player1_rank\", \n",
    "    \"player2_rank\", \n",
    "    \"player1_h2h\", \n",
    "    \"player2_h2h\",\n",
    "    \"surface\", \n",
    "    \"tourney_level\",\n",
    "    \"player_1_theta_form\",\n",
    "    \"player_2_theta_form\",\n",
    "    'player1_surface_win_pct', \n",
    "    'player2_surface_win_pct',\n",
    "    'player1_level_win_pct', \n",
    "    'player2_level_win_pct',]]\n",
    "\n",
    "enginy = engin['maptarget']\n",
    "enginxwith['surface'] = le.fit_transform(enginx['surface'])\n",
    "enginxwith['tourney_level'] = le.fit_transform(enginx['tourney_level'])\n",
    "enginxwithout['surface'] = le.fit_transform(enginx['surface'])\n",
    "enginxwithout['tourney_level'] = le.fit_transform(enginx['tourney_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engintrainxwith, engintestxwith, engintrainy, engintesty = train_test_split(enginxwith, enginy, test_size=0.25, random_state=5323)\n",
    "engintrainxwithout, engintestxwithout, engintrainy, engintesty = train_test_split(enginxwithout, enginy, test_size=0.25, random_state=5323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import Logit\n",
    "\n",
    "logitwith = Logit(engintrainy.astype(int),engintrainxwith).fit()\n",
    "logitwithout = Logit(engintrainy.astype(int),engintrainxwithout).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predswith = logitwith.predict(engintestxwith)\n",
    "predswith = list(map(round,predswith))\n",
    "print(accuracy_score(engintesty, predswith))\n",
    "predswithout = logitwithout.predict(engintestxwithout)\n",
    "predswithout = list(map(round,predswithout))\n",
    "print(accuracy_score(engintesty, predswithout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logitwith.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logitwithout.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tennisnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "791a548851e5d0bb19e0f08af09583cabfb25ccb9dae2520d2075e3a1e1d67e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
